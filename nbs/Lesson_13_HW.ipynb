{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "e10c5ba5-491c-455e-81c5-4d9b4ee6c43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[163], line 107\u001b[0m\n\u001b[1;32m    105\u001b[0m model \u001b[38;5;241m=\u001b[39m Model(num_hidden_layers,ni,nh,no)\n\u001b[1;32m    106\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(X,y)\n\u001b[0;32m--> 107\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 96\u001b[0m, in \u001b[0;36mModel.backward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m---> 96\u001b[0m     \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 26\u001b[0m, in \u001b[0;36mModule.backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[163], line 38\u001b[0m, in \u001b[0;36mLinear.bwd\u001b[0;34m(self, out, inp)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbwd\u001b[39m(\u001b[38;5;28mself\u001b[39m , out , inp):\n\u001b[0;32m---> 38\u001b[0m     inp\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39mg\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "X = torch.randn(5000 , 764)\n",
    "y = torch.randint(0, 9, (5000,))\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# class Module():\n",
    "#     def forward(self,*args):\n",
    "#         raise NotImplementedError(\"Forward Method not implemented\")\n",
    "#     def __call__(self,*args):\n",
    "#         self.args = args\n",
    "#         self.out = self.forward(*args)\n",
    "#         return self.out\n",
    "#     def backward(self): self.bwd(self.out, *self.args)\n",
    "#     def bwd(self,*args): raise Exception('not implemented') \n",
    "\n",
    "    \n",
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        # import pdb ; pdb.set_trace()\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "\n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)\n",
    "    def bwd(self): raise Exception('not implemented')\n",
    "    \n",
    "    \n",
    "class Linear(Module):\n",
    "    def __init__(self, ni , no):\n",
    "        super().__init__()\n",
    "        self.w = torch.randn(ni, no).requires_grad_()\n",
    "        self.b = torch.zeros(no).requires_grad_()\n",
    "    def forward(self,x):\n",
    "        return x@self.w + self.b\n",
    "    def bwd(self , out , inp):\n",
    "        inp.g = self.out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "\n",
    "\n",
    "class Relu(Module):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def forward(self,x):\n",
    "        self.out = x.clamp_min(0.)\n",
    "        return self.out\n",
    "    \n",
    "    def bwd(self,out,inp):\n",
    "        inp.g = (inp>0).float() * out.g\n",
    "        \n",
    "\n",
    "\n",
    "class Mse(Module):\n",
    "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
    "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]\n",
    "                \n",
    "        \n",
    "        \n",
    "\n",
    "class Model(Module):\n",
    "    def __init__(self , num_hidden_layers , ni  , nh , no):\n",
    "        \n",
    "        \n",
    "        self.relu = Relu()\n",
    "        \n",
    "        # Stacking layers\n",
    "        self.l1 = [ Linear(ni,nh) , self.relu ]\n",
    "        self.hidden_layers = []\n",
    "        for _ in range(num_hidden_layers-1):\n",
    "            self.hidden_layers.append(Linear(nh,nh))\n",
    "            self.hidden_layers.append(self.relu)\n",
    "        self.out_layer = [Linear(nh,no)]\n",
    "        \n",
    "        self.layers = self.l1 + self.hidden_layers + self.out_layer\n",
    "        self.mse = Mse() \n",
    "        \n",
    "        \n",
    "    def forward(self,x):    \n",
    "        \n",
    "        for layer in self.layers:\n",
    "            # import pdb ; pdb.set_trace()\n",
    "            x = layer(x)\n",
    "        return x\n",
    "    \n",
    "    def __call__(self,x, y):\n",
    "        x = self.forward(x)\n",
    "        self.loss = self.mse(x , y)\n",
    "        return self.loss\n",
    "    \n",
    "    def backward(self,*args):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers):\n",
    "            l.backward()\n",
    "    \n",
    "            \n",
    "                                     \n",
    "    \n",
    "ni = X.shape[1]\n",
    "nh = 32\n",
    "no = 1\n",
    "num_hidden_layers = 1\n",
    "model = Model(num_hidden_layers,ni,nh,no)\n",
    "loss = model(X,y)\n",
    "model.backward()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "9a9808ef-fd6a-47bf-9225-556fc0ebc3ac",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[158], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m loss \u001b[38;5;241m=\u001b[39m model(X,y)\n\u001b[1;32m      7\u001b[0m loss\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[157], line 105\u001b[0m, in \u001b[0;36mModel.backward\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mreversed\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers):\n\u001b[0;32m--> 105\u001b[0m     \u001b[43ml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[157], line 26\u001b[0m, in \u001b[0;36mModule.backward\u001b[0;34m(self)\u001b[0m\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbackward\u001b[39m(\u001b[38;5;28mself\u001b[39m): \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbwd\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[157], line 38\u001b[0m, in \u001b[0;36mLinear.bwd\u001b[0;34m(self, out, inp)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbwd\u001b[39m(\u001b[38;5;28mself\u001b[39m , out , inp):\n\u001b[0;32m---> 38\u001b[0m     inp\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mt()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m inp\u001b[38;5;241m.\u001b[39mt() \u001b[38;5;241m@\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39mg\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "cc6f71a1-9d17-4732-be3f-b180d4671deb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Module():\n",
    "    def __call__(self, *args):\n",
    "        self.args = args\n",
    "        self.out = self.forward(*args)\n",
    "        return self.out\n",
    "\n",
    "    def forward(self): raise Exception('not implemented')\n",
    "    def backward(self): self.bwd(self.out, *self.args)\n",
    "    def bwd(self): raise Exception('not implemented')\n",
    "\n",
    "class Relu(Module):\n",
    "    def forward(self, inp): return inp.clamp_min(0.)\n",
    "    def bwd(self, out, inp): inp.g = (inp>0).float() * out.g\n",
    "\n",
    "class Lin(Module):\n",
    "    def __init__(self, w, b): \n",
    "        self.w,self.b = w,b\n",
    "    def forward(self, inp): return inp@self.w + self.b\n",
    "    def bwd(self, out, inp):\n",
    "        inp.g = out.g @ self.w.t()\n",
    "        self.w.g = inp.t() @ self.out.g\n",
    "        self.b.g = self.out.g.sum(0)\n",
    "class Mse(Module):\n",
    "    def forward (self, inp, targ): return (inp.squeeze() - targ).pow(2).mean()\n",
    "    def bwd(self, out, inp, targ): inp.g = 2*(inp.squeeze()-targ).unsqueeze(-1) / targ.shape[0]\n",
    "\n",
    "class Model():\n",
    "    def __init__(self, w1, b1, w2, b2):\n",
    "        self.layers = [Lin(w1,b1), Relu(), Lin(w2,b2)]\n",
    "        self.loss = Mse()\n",
    "        \n",
    "    def __call__(self, x, targ):\n",
    "        for l in self.layers: x = l(x)\n",
    "        return self.loss(x, targ)\n",
    "    \n",
    "    def backward(self):\n",
    "        self.loss.backward()\n",
    "        for l in reversed(self.layers): l.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "32144c0f-7998-48e8-b672-20e453a63c7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "w1 = torch.randn(ni,nh)\n",
    "b1 = torch.zeros(nh)\n",
    "w2 = torch.randn(nh,1)\n",
    "b2 = torch.zeros(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30fdd47-1b5d-413c-9c55-ccc7c698efdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "f0c9a00d-a277-4e21-9e8f-c96563ece3bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Model(w1, b1, w2, b2)\n",
    "\n",
    "loss = model(X, y)\n",
    "\n",
    "model.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "d72ff96f-f62c-462b-9288-e0cee61a5249",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'g'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[156], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m     x\u001b[38;5;241m.\u001b[39mg \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      3\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;241m9\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28mprint\u001b[39m(x , \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m)\n\u001b[1;32m      5\u001b[0m tes(x)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(x , x\u001b[38;5;241m.\u001b[39mg)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'g'"
     ]
    }
   ],
   "source": [
    "def tes(*args):\n",
    "    arguments = args\n",
    "    \n",
    "x = torch.tensor(9)\n",
    "tes(x)\n",
    "print(x , x.g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb9f85b7-ea98-4b14-b5bd-34810f01e2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
